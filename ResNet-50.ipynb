{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a2816a-49a1-4a43-9220-d4708bb70b36",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>AI-Generated VS Natural Images Classifier</h1>\n",
    "This notebook demonstrates the process of building a PyTorch-based classifier between AI-Generated and Natural Images. \n",
    "The dataset utilized in this notebook is GenImage, accessible at the following link: https://github.com/GenImage-Dataset/GenImage. The dataset contains huge amount of Natural vs AI-Generated images from various generators. This notebook implements ResNet-50 Fine Tuning to build a classifier model, which has been proven to achieve the highest performance in a similar dataset (https://arxiv.org/abs/2312.08880).<br><br>\n",
    "<div align=center>\n",
    "<img src='visulization.png' width=750>\n",
    "</div>\n",
    "<p style=\"text-align:center;\">Example of GenImage Dataset</p>\n",
    "\n",
    "<br>                                                                                                                       \n",
    "Note: The datasets provided in GenImage share similar structures. Consequently, the process outlined in this notebook can be used to create a classifier model for each dataset.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250219c-4bfa-4b5c-b989-148060c99f3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>Importing Library</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d85d85cc-236c-44b8-8bfd-d393e43f7605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "import torch.cuda  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d773838a-02c1-46d9-9e51-a7467ef043e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>Data Preparation</h2>\n",
    "The dataset is already clean, so it doesn't require much preprocessing aside from resizing and normalization. The data is split with an 80:20 ratio for training and validation. You can modify general variables such as the dataset path, batch size, and CUDA configuration as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd1b32f-3cd6-479a-b4eb-3cfbf8a426e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Data\n",
    "data_dir = 'Dataset/GAN/BigGan/train'\n",
    "# Define transforms for the training and validation sets (adjust the needs)\n",
    "data_transforms ={\n",
    "    \"train_transforms\": transforms.Compose([transforms.RandomRotation(30),\n",
    "                                           transforms.RandomResizedCrop(299), \n",
    "                                           transforms.RandomHorizontalFlip(), \n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                [0.229, 0.224, 0.225])]),\n",
    "   \"valid_transforms\": transforms.Compose([transforms.Resize(300),\n",
    "                                           transforms.CenterCrop(299),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])]), \n",
    "    \"test_transforms\": transforms.Compose([transforms.Resize(300),\n",
    "                                           transforms.CenterCrop(299),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])])\n",
    "}\n",
    "\n",
    "# Set the split ratios for training and validation\n",
    "train_data_ratio = 0.8\n",
    "valid_data_ratio = 0.2\n",
    "\n",
    "# Apply defined data transformation \n",
    "train_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"train_transforms\"])\n",
    "valid_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"valid_transforms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065ae079-af8e-4deb-ad34-d04e7b04d02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : 544000\n",
      "Validation : 136000\n"
     ]
    }
   ],
   "source": [
    "# Obtain training indices that will be used for validation \n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "\n",
    "# Calculate the number of samples for training and validation\n",
    "train_count = int(train_data_ratio * num_train)\n",
    "valid_count = int(valid_data_ratio * num_train)\n",
    "\n",
    "# Split the indices into training and validation\n",
    "train_idx = indices[:train_count]\n",
    "valid_idx = indices[train_count:train_count + valid_count]\n",
    "\n",
    "# Print the percentage of total data each set represents\n",
    "print(\"Training : \", len(train_idx))\n",
    "print(\"Validation : \", valid_count)\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# Define the loader\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size = 16, shuffle = True,num_workers=100)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size = 32, sampler = valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e97fde-fb34-4a04-b089-cfe028272023",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>Defining Model</h2>\n",
    "Load the ResNet-50 architecture with pre-trained weights, adapt the output layer to the current case, and define the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba531737-9ac3-4c83-8849-511b2c66afae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name: conv1\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "-----------------------------------\n",
      "Layer Name: bn1\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-----------------------------------\n",
      "Layer Name: relu\n",
      "ReLU(inplace=True)\n",
      "-----------------------------------\n",
      "Layer Name: maxpool\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "-----------------------------------\n",
      "Layer Name: layer1\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "-----------------------------------\n",
      "Layer Name: layer2\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "-----------------------------------\n",
      "Layer Name: layer3\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "-----------------------------------\n",
      "Layer Name: layer4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "-----------------------------------\n",
      "Layer Name: avgpool\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "-----------------------------------\n",
      "Layer Name: fc\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Load pre-trained ResNet-50\n",
    "model_transfer = models.resnet50(pretrained=True)\n",
    "\n",
    "# Check if GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()\n",
    "    \n",
    "#Specify that each weight in the ResNet-50 architecture will be updated during training.\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "\n",
    "# Add output layer. In this case the ouput is 4 classes\n",
    "n_inputs = model_transfer.fc.in_features \n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "model_transfer.fc = last_layer\n",
    "\n",
    "# If GPU is available, move the model to GPU\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()\n",
    "    \n",
    "#Define and configure the optimizer as needed\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.SGD(model_transfer.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for name, module in model_transfer.named_children():\n",
    "    print(f\"Layer Name: {name}\")\n",
    "    print(module)\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8836bc18-e0cb-4829-8ba3-9b6992b3363b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.cuda  \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2bded1-f999-41a5-b23a-5a09e69f5279",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>Training Function</h2>\n",
    "In this training function, we check the loss value of of training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0169acc7-6dfb-4112-97a5-bc5a63d35382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tTraining Loss: 0.08514\tValidation Loss: 0.01706\n",
      "Validation loss decreased (inf --> 0.01706).\n",
      "Saving Model...\n",
      "Epoch: 2\tTraining Loss: 0.05563\tValidation Loss: 0.02439\n",
      "Saving Model...\n",
      "Epoch: 3\tTraining Loss: 0.05187\tValidation Loss: 0.00808\n",
      "Validation loss decreased (0.01706 --> 0.00808).\n",
      "Saving Model...\n"
     ]
    }
   ],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    '''returns trained model'''\n",
    "    # Initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.inf\n",
    "  \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # Initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "    \n",
    "        # Model training\n",
    "        model.train()\n",
    "        for batch_idx, (data,target) in enumerate(trainloader):\n",
    "            # Move to GPU\n",
    "            if use_cuda:\n",
    "                data,target = data.cuda(), target.cuda()\n",
    "      \n",
    "            # Then, clear (zero out) the gradient of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # Perform the Cross Entropy Loss. Calculate the batch loss.\n",
    "            loss = criterion(output, target)\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # Perform optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # Record the average training loss\n",
    "            train_loss = train_loss + ((1/ (batch_idx + 1 ))*(loss.data-train_loss))\n",
    "      \n",
    "        # Model validation\n",
    "        model.eval()\n",
    "        for batch_idx, (data,target) in enumerate(validloader):\n",
    "            # Move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # Update the average validation loss\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # Calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # Update the average validation loss\n",
    "            valid_loss = valid_loss + ((1/ (batch_idx +1)) * (loss.data - valid_loss))\n",
    "      \n",
    "        # Print training/validation stats\n",
    "        print('Epoch: {} \\tTraining Loss: {:.5f} \\tValidation Loss: {:.5f}'.format(\n",
    "            epoch,\n",
    "            train_loss,\n",
    "            valid_loss))\n",
    "    \n",
    "        # Save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.5f} --> {:.5f}).'.format(\n",
    "                  valid_loss_min,\n",
    "                  valid_loss))\n",
    "            \n",
    "            valid_loss_min = valid_loss\n",
    "        print('Saving Model...')\n",
    "        torch.save(model.state_dict(), 'FineTuning10%Only.pt')\n",
    "    # Return trained model\n",
    "    return model\n",
    "\n",
    "# Define loaders transfer\n",
    "loaders_transfer = {'train': trainloader,\n",
    "                    'valid': validloader}\n",
    "\n",
    "# Train the model (adjust the parameters as needed)\n",
    "model_transfer = train(3, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa372c-45f6-419c-b964-38c47c52e084",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>Testing Function</h2>\n",
    "We evaluate the model performance judging by the overall accuracy. You can adjust the testing data to check your models capability. In this notebook, we test the model to classify between natural and AI-Generated images created from GAN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d103a02-ef1c-4a69-8f1d-3884fa572dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN Testing Result : \n",
      "Test Loss: 0.027351\n",
      "\n",
      "Overall Test Accuracy: 98.975% (11877.0/12000.0)\n",
      "Accuracy for class ai: 98.100% (5886/6000)\n",
      "Accuracy for class nature: 99.850% (5991/6000)\n",
      "Execution Time: 168.1136178970337 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def test(loaders, model1, criterion, use_cuda):\n",
    "    #Monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    #Monitor per-class accuracy\n",
    "    class_correct = np.zeros(len(loaders['test'].dataset.classes))\n",
    "    class_total = np.zeros(len(loaders['test'].dataset.classes))\n",
    "\n",
    "    model1.eval()  # set model into evaluation/testing mode\n",
    "    start_time = time.time()\n",
    "    #Iterating over test data\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        #Move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        model1 = model1.to(data.device)\n",
    "\n",
    "        #Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model1(data)\n",
    "\n",
    "        #Convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "        #Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        #Update average test loss\n",
    "        test_loss += ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "\n",
    "        #Compare predictions to ground truth\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        total += data.size(0)\n",
    "\n",
    "        #Update per-class counts\n",
    "        for i in range(len(loaders['test'].dataset.classes)):\n",
    "            class_correct[i] += pred[target == i].eq(target[target == i].data.view_as(pred[target == i])).sum().item()\n",
    "            class_total[i] += (target == i).sum().item()\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    print('Overall Test Accuracy: {:.3f}% ({}/{})'.format(100. * correct / total, correct, total))\n",
    "\n",
    "    for i, class_name in enumerate(loaders['test'].dataset.classes):\n",
    "        class_acc = 100. * class_correct[i] / class_total[i] if class_total[i] != 0 else 0\n",
    "        print('Accuracy for class {}: {:.3f}% ({}/{})'.format(class_name, class_acc, int(class_correct[i]), int(class_total[i])))\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "    print(f'Execution Time: {execution_time} seconds')\n",
    "\n",
    "print('GAN Testing Result : ') \n",
    "test(loaders_transfer1, dynamic_ensemble_model, criterion_transfer, use_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
